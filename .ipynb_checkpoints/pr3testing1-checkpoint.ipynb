{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ran_state = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train.dat\", \"r\") as fh:\n",
    "    lines = fh.readlines()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8580"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [l.split() for l in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8580"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #def csr_build(docs):\n",
    "#     #build csr w/ our input data, format: index, value, index value.... etc\n",
    "#     #should be even number of len for each line in doc(1 ind, 1 val)\n",
    "#     #index is feature number, value is count of appearance in doc\n",
    "#     #each line is a doc\n",
    "# nrows = len(docs)\n",
    "# nnz = 0\n",
    "# biggest_feature_id = 0\n",
    "# for d in docs:\n",
    "    \n",
    "#     #divide by two because not all are words/indices, half are values\n",
    "#     nnz += len(d) / 2\n",
    "#     #need to only look at values so skip 1 each time..\n",
    "#     for w in range(0, len(d), 2):\n",
    "#         if(biggest_feature_id < int(d[w])):\n",
    "#             biggest_feature_id = int(d[w])\n",
    "            \n",
    "# ncols = biggest_feature_id\n",
    "# #memory\n",
    "# ind = np.zeros(nnz, dtype = np.int)\n",
    "# val = np.zeros(nnz, dtype = np.double)\n",
    "# ptr = np.zeros(nrows+1, dtype = np.int)\n",
    "# n = 0\n",
    "# i = 0\n",
    "\n",
    "# for d in docs:\n",
    "#     for w in range(0, len(d), 2):\n",
    "#         ind[n] = int(d[w])\n",
    "#         val[n] = int(d[w+1])\n",
    "#         n += 1\n",
    "#     ptr[i+1] = n\n",
    "#     i += 1\n",
    "    \n",
    "# mat = csr_matrix((val, ind, ptr), shape=(nrows, ncols), dtype=np.double)\n",
    "    \n",
    "# ####-----#### \n",
    "# #i did this first implementation same as ACT-data3 but i cannot use TruncatedSVD feature decomposition\n",
    "# #on this csr_matrix because I have memory errors because the mapped ind values are extremely high\n",
    "# #thus on the next implementation/example shown I map in dict to track original id to unique general id created by myself\n",
    "# #which lowers the ind values by a TON for memory allocation in truncatedSVD\n",
    "# #print(mat.shape[1])\n",
    "# #print(mat.shape)\n",
    "# #list(ind)       \n",
    "# #len(ind)       \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####DICT######\n",
    "#def csr_build(docs):\n",
    "    #build csr w/ our input data, format: index, value, index value.... etc\n",
    "    #should be even number of len for each line in doc(1 ind, 1 val)\n",
    "    #index is feature number, value is count of appearance in doc\n",
    "    #each line is a doc\n",
    "nrows = len(docs)\n",
    "nnz = 0\n",
    "biggest_feature_id = 0\n",
    "for d in docs:\n",
    "    \n",
    "    #divide by two because not all are words/indices, half are values\n",
    "    nnz += len(d) / 2\n",
    "    #need to only look at values so skip 1 each time..\n",
    "    for w in range(0, len(d), 2):\n",
    "        if(biggest_feature_id < int(d[w])):\n",
    "            biggest_feature_id = int(d[w])\n",
    "            \n",
    "ncols = biggest_feature_id\n",
    "#memory\n",
    "ind = np.zeros(nnz, dtype = np.int)\n",
    "val = np.zeros(nnz, dtype = np.double)\n",
    "ptr = np.zeros(nrows+1, dtype = np.long)\n",
    "ind_dict = dict()\n",
    "n = 0\n",
    "i = 0\n",
    "index = 0\n",
    "for d in docs:\n",
    "    for w in range(0, len(d), 2):\n",
    "        if not d[w] in ind_dict:\n",
    "            ind_dict[d[w]] = index\n",
    "            index+=1\n",
    "        ind[n] = ind_dict[d[w]]\n",
    "        val[n] = int(d[w+1])\n",
    "        n += 1\n",
    "    ptr[i+1] = n\n",
    "    i += 1\n",
    "    \n",
    "mat = csr_matrix((val, ind, ptr), dtype=np.long)\n",
    "# list(ind)\n",
    "# len(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27673"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8580, 27673)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27672"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.shape[1]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find n_components where explained variance still > 90%, use #features-1 to test\n",
    "#used n_iter=5(also default val) b/c it is higher for sparse matrices that may\n",
    "#have slowly decaying spectrum\n",
    "svd = TruncatedSVD(n_components=1500, n_iter=5, random_state=ran_state)\n",
    "svd_test_fit = svd.fit(mat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb5ba5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#explained variance graph\n",
    "plt.plot(np.cumsum(svd.explained_variance_ratio_))\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('cum variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1292\n"
     ]
    }
   ],
   "source": [
    "#calculating n_compoenets required for explained variance of 90%\n",
    "#usually standard is 95% but we want to reduce dimensions a lot so it's easier\n",
    "#to create distance matrix..\n",
    "variance_ratios = svd.explained_variance_ratio_\n",
    "total_variance = 0.0;\n",
    "req_variance = 0.90\n",
    "n = 0\n",
    "#set correct n to 0 so i can check after it is was even set(0 return means not\n",
    "#found within the n_components provided, need to increase\n",
    "correct_n = 0\n",
    "for ratio in variance_ratios:\n",
    "    total_variance += ratio\n",
    "    n += 1\n",
    "    if total_variance >= req_variance:\n",
    "        correct_n = n\n",
    "        break\n",
    "print(correct_n)\n",
    "#100 not enough, increase to 1000 for truncatedSVD call.\n",
    "#1000 not enough either... increase to 1500\n",
    "#1500 not enough either, increase to 2200\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using found n_components perform svd on matrix for features = correct_n\n",
    "#used n_iter=5(also default val) b/c it is higher for sparse matrices that may\n",
    "#have slowly decaying spectrum\n",
    "tsvd = TruncatedSVD(n_components=correct_n, n_iter=5, random_state=ran_state)\n",
    "reduced_X = tsvd.fit_transform(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8580L, 1292L)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.22421399, -0.16990847, -2.4107291 , ..., -0.2263277 ,\n",
       "        0.28811726,  0.24101835])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_X[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8580"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reduced_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not allowed to use distance matrix\n",
    "#test_dist_matrix = sp.spatial.distance.pdist(reduced_X, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not allowed to use distance matrix\n",
    "#test_dist_matrix.shape\n",
    "#shape = 36803910L, remove after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1292"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reduced_X[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_comp(mat, core_border_noise_list, eps):\n",
    "    unconnected_core_clusters = {}\n",
    "    c_count = 0\n",
    "    \n",
    "    #n is for each core point to place inside a cluster by iterating n\n",
    "    for n in range(len(mat)):\n",
    "        clust_exiter = False\n",
    "        #if point within the list is a core point\n",
    "        if core_border_noise_list[n] == 0:\n",
    "            #check if any elements in dict, otherwise insert first core point\n",
    "            if not unconnected_core_clusters:\n",
    "                #create a list(for the cluster)\n",
    "                unconnected_core_clusters[c_count] = []\n",
    "                #insert the id of the core point into the cluster\n",
    "                unconnected_core_clusters[c_count].append(str(n))\n",
    "                #increase the c_count by 1 so the next cluster created is a diff ID\n",
    "                c_count += 1  \n",
    "                continue\n",
    "            #check if any of the points inside any(iterate) of the clusters are within eps   \n",
    "            for i in range(len(unconnected_core_clusters)): #we are looking at each cluster  \n",
    "                #check each element within each cluster list\n",
    "                for j in range(len(unconnected_core_clusters[i])):\n",
    "                    temp_cluster_key = int(unconnected_core_clusters[i][j])\n",
    "                    #check if core point (n) is w/in eps of each element of each cluster list   \n",
    "                    if within_eps(mat[n], mat[temp_cluster_key], eps):\n",
    "                        #it is within eps of one of the points so we add to this cluster\n",
    "                        unconnected_core_clusters[i].append(str(n))\n",
    "                        clust_exiter = True\n",
    "                        break   \n",
    "                if clust_exiter:\n",
    "                    break  \n",
    "            else:\n",
    "                #create new cluster\n",
    "                unconnected_core_clusters[c_count] = []\n",
    "                #put n into new cluster\n",
    "                unconnected_core_clusters[c_count].append(str(n))\n",
    "                c_count += 1\n",
    "    return unconnected_core_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_border_points(mat, core_border_noise_list, core_cluster, eps):\n",
    "    t_c = 0\n",
    "    c_z = 0\n",
    "    c_n = 0\n",
    "    connected_cluster = core_cluster\n",
    "    for n in range(len(core_border_noise_list)):\n",
    "        \n",
    "        cluster_exiter = False\n",
    "        if core_border_noise_list[n] == 1:\n",
    "            c_n += 1\n",
    "            #go through every cluster in dict\n",
    "            for i in range(len(core_cluster)):\n",
    "                for j in range(len(core_cluster[i])):\n",
    "                    temp_cluster_key = int(core_cluster[i][j])\n",
    "                    if within_eps(mat[n], mat[temp_cluster_key], eps):\n",
    "                        connected_cluster[i].append(str(n))\n",
    "                        cluster_exiter = True\n",
    "                        t_c += 1\n",
    "                        break\n",
    "                if cluster_exiter:\n",
    "                    break\n",
    "    print t_c \n",
    "    print c_n\n",
    "    return connected_cluster\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_points(core_border_noise_list, clusters):\n",
    "    noise_cluster = max(clusters.iterkeys()) + 1 # k+1\n",
    "    noise_indexes = []\n",
    "    for i in range(len(core_border_noise_list)):\n",
    "        if core_border_noise_list[i] == 2:\n",
    "            noise_indexes.append(str(i))\n",
    "            \n",
    "    print \"success - noise pts\"\n",
    "    sys.stdout.flush()\n",
    "    clusters[noise_cluster] = noise_indexes\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####-----DBSCAN-----#####\n",
    "#reindent after all things implemented..\n",
    "#what kind of input to take in? np matrix?\n",
    "#def DBScan(matrix, eps, minpts):\n",
    "#can use basic libraries (sqrt, min, max etc). Also, youâ€™re allowed to use the\n",
    "#scipy library to do mathematical operations like the dot products\n",
    "#dot product (a dot b) = a1b1 +.. adbd.. = signal aibi\n",
    "import sys\n",
    "#NOTE I AM NOT USING SYS FOR DBSCAN ONLY TO DISPLAY PRINT STATEMENTS IMMEDIATELY\n",
    "#BECAUSE PYTHON USES LINE BUFFERING IF INTERACTIVELY DONE(JUPYTER NOTEBOOK)\n",
    "\n",
    "def distance(x, y):\n",
    "    dist = np.sqrt(sp.dot(x,x) + sp.dot(y,y) - 2 * sp.dot(x,y))\n",
    "    return dist\n",
    "\n",
    "def within_eps(x, y, eps):\n",
    "    return distance(x,y) <= eps\n",
    "\n",
    "\n",
    "def core_points(mat, eps, minpts):\n",
    "    #use non-core-mat after for checking these to see if border pts\n",
    "    #if core then true else(border or noise check next fcn) false\n",
    "    testing = 0\n",
    "    core_point_index_list = np.zeros(len(mat), dtype=np.bool)\n",
    "    print \"finding core points\"\n",
    "    sys.stdout.flush()\n",
    "    for i in range(len(mat)):\n",
    "        #reset for every outerloop so check inner loop for 0 -> minpts\n",
    "        current_min_pts = 0\n",
    "        #variable to check if core point was found, if not add to non core point list\n",
    "        if_nocore = False\n",
    "        for j in range(len(mat)):\n",
    "            #print \"i: \", i, \"j: \", j\n",
    "            \n",
    "            if i==j:\n",
    "                #print \"skip this i=j\", i\n",
    "                continue\n",
    "            \n",
    "            if current_min_pts == minpts-1:\n",
    "                if within_eps(mat[i], mat[j], eps):\n",
    "                    current_min_pts += 1\n",
    "                    core_point_index_list[i]=True\n",
    "                    #print \"core point\", i\n",
    "                    if_nocore = True\n",
    "                    break\n",
    "            \n",
    "            elif current_min_pts < minpts:\n",
    "                if within_eps(mat[i], mat[j], eps):\n",
    "                    current_min_pts += 1\n",
    "                    #print i, \"within eps of \", j\n",
    "            \n",
    "            else:\n",
    "                core_point_index_list[i]=True\n",
    "                #print \"core point\", i\n",
    "                if_nocore = True\n",
    "                break\n",
    "        \n",
    "        if not if_nocore:\n",
    "            core_point_index_list[i]=False\n",
    "            #print \"non core point\", i\n",
    "    print \"Done finding core points\"\n",
    "    sys.stdout.flush()\n",
    "    core_border_list = border_points(mat, core_point_index_list, eps)\n",
    "    connected_comps = connect_comp(mat, core_border_list, eps)\n",
    "    #connect_cores\n",
    "    nonoise_clusters = add_border_points(mat, core_border_list, connected_comps, eps)\n",
    "    clusters = add_noise_points(core_border_list, nonoise_clusters)\n",
    "    return clusters \n",
    "\n",
    "#for border list, 0 is core point, 1 is border point, 2 is noise point\n",
    "def border_points(mat, core_point_list, eps):\n",
    "    core_border_list = np.zeros(len(mat), dtype=np.int)\n",
    "    print \"finding border and noise points\"\n",
    "    sys.stdout.flush()\n",
    "    #core_border_list = []\n",
    "    for j in range(len(mat)):\n",
    "        if core_point_list[j]:\n",
    "            core_border_list[j] = 0 #0 means it is a core point\n",
    "            #core_border_list.append(0)\n",
    "        else:\n",
    "            for i in range(len(mat)):\n",
    "                if j == i:\n",
    "                    continue\n",
    "                \n",
    "                elif core_point_list[i] and within_eps(mat[j], mat[i], eps):\n",
    "                    core_border_list[j] = 1 #1 means it is a border point\n",
    "                    #core_border_list.append(1)\n",
    "                    break\n",
    "            #this else statement only executes if the whole forloop is iterated without\n",
    "            #break being called, e.g. never determined to be a border point\n",
    "            else: \n",
    "                core_border_list[j] = 2 #2 means it is a noise point\n",
    "                #core_border_list.append(2)\n",
    "    print \"Done finding border and noise points\"\n",
    "    sys.stdout.flush()\n",
    "    return core_border_list\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def connect_cores(mat, unconnected_clusters, eps):\n",
    "#     connected_core_clusters = {}\n",
    "#     c_count = 0\n",
    "#     #for each non comp unconnected cluster:\n",
    "#     for n in range(len(unconnected_clusters)):\n",
    "#         if not connected_core_clusters:\n",
    "#             connected_core_clusters[c_count] = []\n",
    "#             connected_core_clusters[c_count].append(unconnected_clusters[n])\n",
    "#         #looking through elements of nth cluster\n",
    "#         for i in range(len(unconnected_clusters[n])):\n",
    "#             n_temp_cluster_key = int(unconnected_clusters[n][j])           \n",
    "#             #for each comparison cluster except the nth one or anything before that\n",
    "#             #will skip the last since in range last element not included for up to variable\n",
    "#             for j in range(n+1, len(unconnected_clusters)):\n",
    "#                 #skip if n == j\n",
    "#                 if n == j:\n",
    "#                     continue\n",
    "#                 #looking through each element of the jth cluster/comparison cluster\n",
    "#                 for k in range(len(unconnected_clusters[j])):\n",
    "#                     j_temp_cluster_key = int(unconnected_clusters[j][k])\n",
    "#                     if within_eps(mat[n_temp_cluster_key], mat[j_temp_cluster_key], eps):\n",
    "#                         #add every element of kth cluster to connected_core_clusters\n",
    "#                         connected_core_clusters[c_count].append(unconnected_clusters[j])\n",
    "                            \n",
    "                        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DBScan(mat, minpts, eps):\n",
    "    clusters = core_points(mat, eps, minpts)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding core points\n",
      "Done finding core points\n",
      "finding border and noise points\n",
      "Done finding border and noise points\n",
      "82\n",
      "82\n",
      "success - noise pts\n"
     ]
    }
   ],
   "source": [
    "eps = 7\n",
    "minpts = 3\n",
    "mat = reduced_X\n",
    "clusters = DBScan(mat, minpts, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8580\n"
     ]
    }
   ],
   "source": [
    "###-----exporting CLUSTERS to csv-----###\n",
    "import pandas as pd\n",
    "##THIS IS NOT PART OF MY DBSCAN ALGORITHM, THIS IS JUST EXPORTING TO PREDICTIONS FILE##\n",
    "np_preds = np.zeros(len(reduced_X), dtype=np.int)\n",
    "print(len(np_preds))\n",
    "for i in range(len(clusters)):\n",
    "    for n in range(len(clusters[i])):\n",
    "        #get the index of each of element of every cluster(i)(n)\n",
    "        #as well as the index of the cluster(i) to predict\n",
    "        index_label = int(clusters[i][n])\n",
    "        np_preds[index_label] = i\n",
    "test_df = pd.DataFrame(np_preds)\n",
    "test_df.to_csv(\"predict.dat\", index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #testing add border pts\n",
    "# tclus = add_border_points(reduced_X, reduced_X_core_list, unconnected_clusters, test_eps)\n",
    "# core_num = 0\n",
    "# for key, value in tclus.items():\n",
    "#     print(key, len([item for item in value if item]))\n",
    "#     core_num += len([item for item in value if item])\n",
    "# print core_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #testing connect_comp\n",
    "# unconnected_clusters = connect_comp(reduced_X, reduced_X_core_list, test_eps)\n",
    "\n",
    "# core_num = 0\n",
    "# for key, value in unconnected_clusters.items():\n",
    "#     print(key, len([item for item in value if item]))\n",
    "#     core_num += len([item for item in value if item])\n",
    "# print core_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #testing border, noise and core point finder using core_points and border_points\n",
    "# #(intenal call)\n",
    "# len(reduced_X)\n",
    "# test_eps = 7\n",
    "# test_min = 3\n",
    "# reduced_X_core_list = core_points(reduced_X, test_eps, test_min)\n",
    "# print(len(reduced_X_core_list))\n",
    "# unique_items, counts = np.unique(reduced_X_core_list, return_counts=True)\n",
    "# print(unique_items)\n",
    "# print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #testing core_points\n",
    "# test_matrix = [[2,4],[5,7],[9,10],[3,1]]\n",
    "# test_eps = 7\n",
    "# test_min = 3\n",
    "# test_matrix_core_point_list = core_points(test_matrix, test_eps, test_min)\n",
    "\n",
    "# print(len(test_matrix_core_point_list))\n",
    "# print(test_matrix_core_point_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #testing distance def...\n",
    "# t1 = np.array([2,4,6])\n",
    "# t2 = np.array([3,6,9])\n",
    "\n",
    "# t_dist = distance(t1,t2)\n",
    "# print(t_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #testing within_eps\n",
    "# t1 = np.array([2,4,6])\n",
    "# t2 = np.array([3,6,9])\n",
    "\n",
    "# t_eps_check = within_eps(t1,t2, 3.0)\n",
    "# print(t_eps_check)\n",
    "# #eucl dist is ~3.71 so > 3.0 not in eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #testing within_eps\n",
    "# t1 = np.array([2,4,6])\n",
    "# t2 = np.array([3,6,9])\n",
    "\n",
    "# t_eps_check = within_eps(t1,t2, 4.0)\n",
    "# print(t_eps_check)\n",
    "# #eucl dist is ~3.71 so < 4.0 not in eps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
